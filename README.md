# w207_final_project_Cluster-F  

1) Download csv's from kaggle and put into folder ../input  
2) Run make_mini_datasets.py  
3) Run Data wrangling.ipynb  

Ideas: 
Have we tried [Dask DataFrame](http://dask.pydata.org/en/latest/dataframe.html) or [Pyspark + pandas] (https://spark.apache.org/docs/2.0.0/sql-programming-guide.html#generic-loadsave-functions) for getting the large files down? My office had a talk today that brought this up and I wanted to pass it on. I need to finish a 205 project tonight (Tuesday) but can look into it on Wednesday if we want.
