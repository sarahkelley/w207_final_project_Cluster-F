{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# importing ML libraries\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# importing visual analysis \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#click_train_data= pd.read_csv(\"clicks_train_features.csv\")\n",
    "train_data = pd.read_csv('trainingdata.csv')\n",
    "train_labels = pd.read_csv('traininglabels.csv')\n",
    "dev_data = pd.read_csv('developmentdata.csv')\n",
    "dev_labels =pd.read_csv('developmentlabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert train labels into an array, so sklearn accepts them\n",
    "train_labels =train_labels[\"0\"]\n",
    "dev_labels = dev_labels[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get rid of the categorical variables we can't use for regression and decision trees\n",
    "full_train = train_data[train_data.columns[11:]].fillna(0)\n",
    "full_dev = dev_data[dev_data.columns[11:]].fillna(0)\n",
    "#Make small version of the data for GridSearch (otherwise it is unbelieveably slow)\n",
    "mini_train =full_train[:5000]\n",
    "mini_dev = full_train[5000:7000]\n",
    "mini_train_labels = train_labels[:5000]\n",
    "mini_dev_labels = train_labels[5000:7000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale:** \n",
    "We started with logistic regression (we could not use linear since we have a binary response variable) since the large number of cases would make it more accurate than techniques like Naive Bayes.\n",
    "Although some of the regession assumptions are violated (chiefly multifolinearity), we decided to continue anyway because the focus of this challenge is getting the best prediction rather than identifying accurately the size of each individual coefficient.\n",
    "\n",
    "**Approach:**\n",
    "We first fit a logistic regression model without regularization, using all the binarized features (representing document category, topic etc) and continuous features reprenting the percent of ads from that ad campaign that had been clicked, the percent of ads from that advertiser that had been clicked, the frequency of document views, and the percentage of that ad that had been clicked.\n",
    "\n",
    "Then we use grid search to identify the optimal level of regularization and whether l2 or l1 regularization would perform better. We expected l1 regularization to be superior because it more harshly penalizes very low weighted features. \n",
    "\n",
    "Finally, we tried exercising our domain knowledge/judgement and running a regression with only the four predictors we expected to be most predictive, which were the percent of ads from that ad campaign that had been clicked, the percent of ads from that advertiser that had been clicked, the frequency of document views, and the percentage of that ad that had been clicked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration of Some Key Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The click percent is correlated 0.866557250489 with the campaign percent.\n",
      "The advertiser percent is correlated 0.831655161645 with the campaign percent.\n",
      "The advertiser percent is correlated 0.811708146085 with the click percent\n",
      "The advertiser percent is correlated 0.08089912812 with document frequency.\n",
      "Other representative variables are not excessively correlated.\n",
      "0.000134479244919\n",
      "0.00135907055519\n",
      "-0.000873503139683\n",
      "0.00696351770159\n",
      "0.00516579974675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11aaa35c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngBQtLf4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1136b6cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multicollinearity\n",
    "print(\"The click percent is correlated\", train_data['click_perc'].corr(train_data['campaign_perc']), \"with the campaign percent.\")\n",
    "print(\"The advertiser percent is correlated\", train_data['advertiser_perc'].corr(train_data['campaign_perc']), 'with the campaign percent.')\n",
    "print(\"The advertiser percent is correlated\",train_data['advertiser_perc'].corr(train_data['click_perc']), 'with the click percent')\n",
    "print(\"The advertiser percent is correlated\", train_data['advertiser_perc'].corr(train_data['docx_view_freq']), \"with document frequency.\")\n",
    "print(\"Other representative variables are not excessively correlated.\")\n",
    "print(train_data['cat_1000'].corr(train_data['cat_1210']))\n",
    "print(train_data['top_200'].corr(train_data['cat_1210']))\n",
    "print(train_data['cat_1000'].corr(train_data['top_130']))\n",
    "print(train_data['cat_1000'].corr(train_data['campaign_perc']))\n",
    "print(train_data['cat_1000'].corr(train_data['click_perc']))\n",
    "\n",
    "\n",
    "# there are some higher correlations between advertiser_perc, campaign_perc, and click_perc which make sense\n",
    "# because advertisers have their own campaigns and each advertisement belongs to an advertiser and a campaign\n",
    "\n",
    "# Shape of Predictor Variables\n",
    "train_data['advertiser_perc'].hist()\n",
    "np.log1p(train_data['advertiser_perc']).hist()\n",
    "# transformation didn't make that much more normal, but normality is a weaker assumption that doesn't have to be fulfilled..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Regression with all features, unregularized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.859842668494 using all possible features\n"
     ]
    }
   ],
   "source": [
    "#with all regressable features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(full_train, train_labels)\n",
    "lr_score_1 = lr.score(full_dev, dev_labels)\n",
    "print(\"The accuracy is\", lr_score_1, \"using all possible features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Regression using regularization to reduce features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.860161583709 using regularization with the best parameters idenfitied by grid search.\n",
      "These parameters are: l1 penalty and 0.5 C.\n",
      "This leaves 126 non-zero parameters.\n",
      "These features are ['top_0', 'top_1', 'top_2', 'top_8', 'top_11', 'top_16', 'top_20', 'top_26', 'top_36', 'top_37', 'top_43', 'top_44', 'top_52', 'top_61', 'top_64', 'top_66', 'top_68', 'top_74', 'top_85', 'top_92', 'top_93', 'top_97', 'top_102', 'top_107', 'top_113', 'top_127', 'top_131', 'top_136', 'top_138', 'top_140', 'top_147', 'top_148', 'top_154', 'top_160', 'top_161', 'top_174', 'top_183', 'top_184', 'top_185', 'top_191', 'top_192', 'top_198', 'top_199', 'top_215', 'top_227', 'top_232', 'top_238', 'top_239', 'top_240', 'top_249', 'top_250', 'top_265', 'top_271', 'top_287', 'top_291', 'top_292', 'top_294', 'top_296', 'cat_1100', 'cat_1202', 'cat_1203', 'cat_1204', 'cat_1205', 'cat_1206', 'cat_1207', 'cat_1208', 'cat_1210', 'cat_1211', 'cat_1302', 'cat_1303', 'cat_1402', 'cat_1403', 'cat_1405', 'cat_1406', 'cat_1407', 'cat_1408', 'cat_1502', 'cat_1503', 'cat_1504', 'cat_1505', 'cat_1506', 'cat_1509', 'cat_1513', 'cat_1514', 'cat_1515', 'cat_1516', 'cat_1602', 'cat_1603', 'cat_1604', 'cat_1606', 'cat_1607', 'cat_1608', 'cat_1609', 'cat_1610', 'cat_1611', 'cat_1612', 'cat_1613', 'cat_1702', 'cat_1703', 'cat_1706', 'cat_1708', 'cat_1709', 'cat_1711', 'cat_1804', 'cat_1805', 'cat_1806', 'cat_1807', 'cat_1808', 'cat_1809', 'cat_1903', 'cat_1904', 'cat_1907', 'cat_1908', 'cat_1910', 'cat_1911', 'cat_1912', 'cat_1913', 'cat_2002', 'cat_2003', 'cat_2004', 'cat_2005', 'cat_2100', 'advertiser_perc', 'campaign_perc', 'docx_view_freq', 'click_perc']\n"
     ]
    }
   ],
   "source": [
    "#grid search runs on the smaller data because running it on the full data takes too long for a demo notebook\n",
    "lr = LogisticRegression()\n",
    "C = {\"C\": [.01, .05, 0.1, .2, .5, 1 , 10, 100], 'penalty':[\"l1\", \"l2\"]}\n",
    "search = GridSearchCV(lr, param_grid = C)\n",
    "lr_params = search.fit(full_train, train_labels)\n",
    "lr_best = lr_params.best_params_\n",
    "lr = LogisticRegression(C= lr_best[\"C\"], penalty = lr_best[\"penalty\"])\n",
    "lr.fit(full_train, train_labels)\n",
    "lr_score_2 = lr.score(full_dev, dev_labels)\n",
    "print(\"The accuracy is\", lr_score_2, \"using regularization with the best parameters idenfitied by grid search.\")\n",
    "print (\"These parameters are:\", lr_best[\"penalty\"], 'penalty and',lr_best[\"C\"], 'C.')\n",
    "print (\"This leaves\", np.count_nonzero(lr.coef_), \"non-zero parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features with the largest coefficients: (with a caveat that multicolinearity complicates interpreting the coefficients of the four % features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396    campaign_perc\n",
       "398       click_perc\n",
       "184          top_184\n",
       "174          top_174\n",
       "238          top_238\n",
       "8              top_8\n",
       "199          top_199\n",
       "37            top_37\n",
       "131          top_131\n",
       "382         cat_1910\n",
       "Name: cols, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = list(lr.coef_[0])\n",
    "cols = list(mini_train.columns.values)\n",
    "feature_imp = pd.DataFrame({\"coef\":coef, \"cols\": cols})\n",
    "feature_imp.tail()\n",
    "feature_imp.sort_values('coef', ascending = False, inplace = True)\n",
    "feature_imp['cols'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Classification Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92     72008\n",
      "          1       0.65      0.14      0.23     12654\n",
      "\n",
      "avg / total       0.83      0.86      0.82     84662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = lr.predict(full_dev)\n",
    "print(classification_report(dev_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall especially for class 1 ('clicked\") is abysmally low, with a low f1-score as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Regression Model Training using the Four 'Logically' chosen Groups **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.85996078524 using the top 'logically chosen' features.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(full_train[full_train.columns[-4:]], train_labels)\n",
    "lr_score_3 = lr.score(full_dev[full_dev.columns[-4:]], dev_labels)\n",
    "print(\"The accuracy is\", lr_score_3, \"using the top 'logically chosen' features.\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Conclusions:\n",
    "Regularization doesn't make much of difference.\n",
    "The highest accuracy achieved is about 86%. \n",
    "The 4 added features performed well, although only campaign % clicked and ad % clicked were in the top 10 largest coeficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale:** A random forest algorithm seemed like the perfect technique to approach this since it is a classification problem (ads are either clicked or not clicked) and we had a very large number of features, many of which are likely irrelevant. Random Forest models address decision trees issues with over fitting by averaging the results of many different decision trees trained on different sub samples of the data. This increases variance but decreases bias, leading to more accurate prediction on test data. \n",
    "\n",
    "**Approach:** We trained first a standard decision tree, and then trained a random forest model using grid search to optimize the maximum number of features the trees would use, the number of trees, and the information gain criterion (either gini or entropy). We then scored the model using the best features. \n",
    "We also then fit an extra trees model, which tends towards a larger number of leaves, using the same grid search parameters as with the random forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Single Decision Tree **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single decision tree got an accuracy of 0.846649027899\n"
     ]
    }
   ],
   "source": [
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "dec_tree = dec_tree.fit(full_train, train_labels)\n",
    "print(\"A single decision tree got an accuracy of\", dec_tree.score(full_dev, dev_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Baseline Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84429850464198819"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state = 1)\n",
    "forest = forest.fit(full_train, train_labels)\n",
    "forest.score(full_dev, dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random forest with grid search to identify optimal parameters **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random forest with optimal parameters got an accuracy of 0.858283527439\n",
      "With 200 trees and gini as the criterion\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[10, 50, 100, 200], 'criterion': [\"gini\", \"entropy\"]}\n",
    "forest = RandomForestClassifier(random_state = 1)\n",
    "search = GridSearchCV(forest, param_grid = parameters, scoring = \"f1_micro\")\n",
    "forest_params = search.fit(mini_train, mini_train_labels)\n",
    "forest_best = forest_params.best_params_\n",
    "forest = RandomForestClassifier(random_state = 1, max_features = 'auto', n_estimators = forest_best['n_estimators'], criterion = forest_best['criterion'])\n",
    "forest.fit(full_train, train_labels)\n",
    "forest.score(full_dev, dev_labels)\n",
    "print(\"A random forest with optimal parameters got an accuracy of\", forest.score(full_dev, dev_labels))\n",
    "print(\"With\", forest_best['n_estimators'], 'trees and', forest_best['criterion'], \"as the criterion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397     docx_view_freq\n",
       "398         click_perc\n",
       "396      campaign_perc\n",
       "395    advertiser_perc\n",
       "376           cat_1903\n",
       "183            top_183\n",
       "321           cat_1403\n",
       "160            top_160\n",
       "326           cat_1408\n",
       "379           cat_1907\n",
       "Name: cols, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = forest.feature_importances_\n",
    "features = list(forest.feature_importances_)\n",
    "cols = list(mini_train.columns.values)\n",
    "feature_imp = pd.DataFrame({\"features\":features, \"cols\": cols})\n",
    "feature_imp.sort_values('features', ascending = False, inplace = True)\n",
    "feature_imp['cols'][:10]\n",
    "#features[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four engineered features were the 4 most important features in forming this random forest, followed by other binary variables for certain categories and topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92     72008\n",
      "          1       0.59      0.18      0.27     12654\n",
      "\n",
      "avg / total       0.83      0.86      0.82     84662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = forest.predict(full_dev)\n",
    "print(classification_report(dev_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores for predicting class 1 (an ad was clicked) are much much lower than for predicting an ad not being clicked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Extra Trees with grid search to identify optimal parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Extra Trees forest with optimal parameters got an accuracy of 0.837908388651\n",
      "With 10 trees and  entropy as the criterion\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[10, 50, 100, 200], 'criterion': [\"gini\", \"entropy\"]}\n",
    "extrees = ExtraTreesClassifier(random_state = 1)\n",
    "search = GridSearchCV(extrees, param_grid = parameters, scoring = \"f1_micro\")\n",
    "extrees_params = search.fit(mini_train, mini_train_labels)\n",
    "extrees_best = extrees_params.best_params_\n",
    "trees = ExtraTreesClassifier(random_state = 1, max_features = 'auto', n_estimators = forest_best['n_estimators'], criterion = forest_best['criterion'])\n",
    "extrees.fit(full_train, train_labels)\n",
    "extrees.score(full_dev, dev_labels)\n",
    "print(\"A Extra Trees forest with optimal parameters got an accuracy of\", extrees.score(full_dev, dev_labels))\n",
    "print(\"With\", extrees_best['n_estimators'], 'trees and ', extrees_best['criterion'], \"as the criterion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Conclusion:\n",
    "Random Forest performs slightly better than a single decision and has a very similar accuracy to that of regression (.86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale:** Kmeans is not necessarily the ideal approach because it assumes that each feature is equally important -- it minimizes distance in all features equally -- which is clearly not the case here. Nevertheless, we decided to try.\n",
    "\n",
    "**Approach** We tried first kmeans on the full features with 1, 3, 5, and 10 neighbours. Then we tried it using a smaller subset of features - only the four specifically engineered features, but got similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Model with full features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 :              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.84      0.85     72008\n",
      "          1       0.24      0.28      0.26     12654\n",
      "\n",
      "avg / total       0.77      0.76      0.76     84662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def kmeans(k_values):\n",
    "\n",
    "    for i in k_values:\n",
    "        neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "        neigh.fit(full_train, train_labels)\n",
    "        preds = neigh.predict(full_dev)\n",
    "        print(\"k=\",i,\":\",classification_report(dev_labels, preds))\n",
    "\n",
    "k_values = [1, 3, 5, 10]\n",
    "kmeans(k_values)\n",
    "\n",
    "# the prediction accuracy is still somewhat low\n",
    "# the recall and precision of predicting an ad that was clicked (1) is extremeley low even with overfitting,\n",
    "# so with more generalization and higher k-values, we don't expect much better.\n",
    "\n",
    "# try again but only with the engineered variables of clicks, not including category/topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Reduced Feature Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 :              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.84      0.86     72008\n",
      "          1       0.25      0.30      0.27     12654\n",
      "\n",
      "avg / total       0.78      0.76      0.77     84662\n",
      "\n",
      "k= 3 :              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.91      0.89     72008\n",
      "          1       0.32      0.24      0.27     12654\n",
      "\n",
      "avg / total       0.79      0.81      0.80     84662\n",
      "\n",
      "k= 5 :              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.94      0.90     72008\n",
      "          1       0.36      0.20      0.26     12654\n",
      "\n",
      "avg / total       0.79      0.83      0.81     84662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def kmeans2(k_values):\n",
    "\n",
    "    for i in k_values:\n",
    "        neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "        neigh.fit(full_train[full_train.columns[-4:]], train_labels)\n",
    "        preds = neigh.predict(full_dev[full_dev.columns[-4:]])\n",
    "        print(\"k=\",i,\":\",classification_report(dev_labels, preds))\n",
    "\n",
    "k_values = [1, 3, 5, 10]\n",
    "kmeans2(k_values)\n",
    "\n",
    "# even running on the last 4 columns, feature engineered to look at overall averages of clicks based on \n",
    "# other features like advertiser, campaign do not improve accuracy much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Added Additional Feature **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 :              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.84      0.86     72008\n",
      "          1       0.26      0.31      0.28     12654\n",
      "\n",
      "avg / total       0.78      0.76      0.77     84662\n",
      "\n",
      "k= 3 :              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.93      0.90     72008\n",
      "          1       0.35      0.22      0.27     12654\n",
      "\n",
      "avg / total       0.79      0.82      0.80     84662\n",
      "\n",
      "k= 5 :              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.95      0.91     72008\n",
      "          1       0.38      0.19      0.25     12654\n",
      "\n",
      "avg / total       0.80      0.83      0.81     84662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try binarizing platform & advertiser_id as more features for kmeans\n",
    "# kmeans finds similar neighbors, calculates dissimilarity distances between rows\n",
    "# so more differentiating factors can help kmeans find 'similar' neighbors for prediction\n",
    "# advertiser and platform may be good features that differentiate clicks\n",
    "\n",
    "# advertiser may take a while and kill the kernel, so feel free to keep it commented out\n",
    "\n",
    "#advertiser = pd.get_dummies(train_data, columns={'advertiser_id'}, prefix=\"advertiser\")\n",
    "platform = pd.get_dummies(train_data.fillna(0), columns={'platform'}, prefix=\"platform\")\n",
    "train_data_kmeans = platform[platform.columns[:1].union(platform.columns[405:])]\n",
    "#train_data_kmeans = train_data_kmeans.merge(advertiser[advertiser.columns[:1].union(advertiser.columns[409:])], on='display_id')\n",
    "del train_data_kmeans[\"display_id\"]\n",
    "\n",
    "#advertiser_dev = pd.get_dummies(dev_data, columns={'advertiser_id'}, prefix=\"advertiser\")\n",
    "platform_dev = pd.get_dummies(dev_data.fillna(0), columns={'platform'}, prefix=\"platform\")\n",
    "dev_data_kmeans = platform_dev[platform_dev.columns[:1].union(platform_dev.columns[405:])]\n",
    "#dev_data_kmeans = dev_data_kmeans.merge(advertiser_dev[advertiser_dev.columns[:1].union(advertiser_dev.columns[409:])], on='display_id')\n",
    "del dev_data_kmeans[\"display_id\"]\n",
    "\n",
    "def kmeans3(k_values):\n",
    "\n",
    "    for i in k_values:\n",
    "        neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "        neigh.fit(train_data_kmeans, train_labels)\n",
    "        preds = neigh.predict(dev_data_kmeans)\n",
    "        print(\"k=\",i,\":\",classification_report(dev_labels, preds))\n",
    "\n",
    "k_values = [1, 3, 5]\n",
    "kmeans3(k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Conclusion:\n",
    "Kmeans did not do a good job of predicting the correct \"clicked\" ads, the recall and precision of class 1 (clicked) was ~25% which is still not great. The overall f-score of ~.80 is not bad though. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression and random forest models produced similar accuracies (around 86%). \n",
    "\n",
    "Given the nature of the data - many irrelevant features and strong multicolinearity between some features - random forest is the logically best choice and since it is equally effective, we will conclude that our final model is a Random Forest, with 200 trees and gini as the evaluation criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
