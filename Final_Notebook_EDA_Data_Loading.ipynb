{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outbrain Click Prediction Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Submitted by Jay Cordes, Sarah Kelly, Nicole Lee, and Lisa Minas_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Background and Modeling Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outbrain is looking to predict which ad in a given display will be clicked by a user. They have provided an extensive amount of information about where an ad is displayed, what the ad is displaying, and user activity on multiple publisher sites in the United States between 14-June-2016 and 28-June-2016. Based on this information, we are asked to order by decending probability which ad within a display a user will click. \n",
    "\n",
    "We plan to approach this problem in a step-wise process. First, we will explore the data to better understand what information has been provided. Based on our initial investigation, we will transform the data to fit with the machine learning models we expect to be most appropriate for predicting clicks. If we find potential value in multiple models, we will quickly score a trained model on development data to determine which model we should focus on for optimization. Once a final model is chosen, we will further refine the model and judiciously score against the development model. Our final score will be determined by testing against a provided test dataset (clicks_test) and by the score judged via Kaggle.\n",
    "\n",
    "Note: We are running this notebook in Python3 because Kaggle uses Python3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load all of the datasets and save them to files we will not overwrite. These files are very large and take a while to download. To avoid re-downloading multiple times through development, we found it easiest to create copies of the original files that we could re-refer to when needing to adjust our transformations.\n",
    "\n",
    "Based on documentation, platform and traffic_source should be 1 of three values: 1, 2, 3. We discovered through EDA that these numbers came in as both ints and strs. To clean them up, we added a dtype statement to the read_csv below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# importing general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# importing ML libraries\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# importing visual analysis \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading all of the files\n",
    "clicks_train_og = pd.read_csv(\"../input/clicks_train.csv\")\n",
    "promoted_content_og = pd.read_csv(\"../input/promoted_content.csv\")\n",
    "doc_cats_og = pd.read_csv(\"../input/documents_categories.csv\")\n",
    "doc_ents_og = pd.read_csv(\"../input/documents_entities.csv\")\n",
    "doc_meta_og = pd.read_csv(\"../input/documents_meta.csv\")\n",
    "doc_topics_og = pd.read_csv(\"../input/documents_topics.csv\")\n",
    "events_og = pd.read_csv(\"../input/events.csv\", dtype={'platform': str, 'geo_location': str})\n",
    "page_views_og = pd.read_csv(\"../input/page_views_sample.csv\", dtype={'platform': str, 'traffic_source': str, 'geo_location': str})\n",
    "clicks_test_og = pd.read_csv(\"../input/clicks_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size has turned into a major issue with this project. Outbrain provided 9 CSVs of data averaging over 100 MB in compressed form with one file that is over 2 billion rows and 100GB uncompressed. This file is so large, Outbrain provided a 10th file which is a smaller sample to use for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicks_train size is: (87141731, 3)\n",
      "Clicks_test size is: (32225162, 2)\n",
      "Promoted Content size is: (559583, 4)\n",
      "Document Categories size is: (5481475, 3)\n",
      "Document Entities size is: (5537552, 3)\n",
      "Document Meta size is: (2999334, 4)\n",
      "Document Topics size is: (11325960, 3)\n",
      "Events size is: (23120126, 6)\n",
      "Page Views size is: (9999999, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Clicks_train size is: {}\".format(clicks_train_og.shape))\n",
    "print(\"Clicks_test size is: {}\".format(clicks_test_og.shape))\n",
    "print(\"Promoted Content size is: {}\".format(promoted_content_og.shape))\n",
    "print(\"Document Categories size is: {}\".format(doc_cats_og.shape))\n",
    "print(\"Document Entities size is: {}\".format(doc_ents_og.shape))\n",
    "print(\"Document Meta size is: {}\".format(doc_meta_og.shape))\n",
    "print(\"Document Topics size is: {}\".format(doc_topics_og.shape))\n",
    "print(\"Events size is: {}\".format(events_og.shape))\n",
    "print(\"Page Views size is: {}\".format(page_views_og.shape)) # note: full page views is ~100GB uncompressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's explore what we're training on: clicks_train and clicks test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicks_train:\n",
      "   display_id   ad_id  clicked\n",
      "0           1   42337        0\n",
      "1           1  139684        0\n",
      "2           1  144739        1\n",
      "3           1  156824        0\n",
      "4           1  279295        0\n",
      "\n",
      "Clicks_test:\n",
      "   display_id   ad_id\n",
      "0    16874594   66758\n",
      "1    16874594  150083\n",
      "2    16874594  162754\n",
      "3    16874594  170392\n",
      "4    16874594  172888\n"
     ]
    }
   ],
   "source": [
    "print(\"Clicks_train:\")\n",
    "print(clicks_train_og.head())\n",
    "print(\"\\nClicks_test:\")\n",
    "print(clicks_test_og.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that test does not have the clicked label. To score our models as we build, we need to have a development set that we can predict and verify success against a known label. If we don't have a set-aside testing dataset, we'll likely overfit our model to the training data and have poorer results when scoring clicks_test and the hidden kaggle testind dataset. Therefore we will break the training data into training and development with a 70%-30% split. Otherwise, the two datasets look very similar. But display_id is the same for these first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    display_id   ad_id  clicked\n",
      "0            1   42337        0\n",
      "1            1  139684        0\n",
      "2            1  144739        1\n",
      "3            1  156824        0\n",
      "4            1  279295        0\n",
      "5            1  296965        0\n",
      "6            2  125211        0\n",
      "7            2  156535        0\n",
      "8            2  169564        0\n",
      "9            2  308455        1\n",
      "10           3   71547        0\n",
      "11           3   95814        0\n",
      "12           3  152141        0\n",
      "13           3  183846        0\n",
      "14           3  228657        1\n",
      "15           3  250082        0\n"
     ]
    }
   ],
   "source": [
    "print(clicks_train_og[clicks_train_og.display_id < 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few display_ids show us that there's multiple ad_ids per display_id. Within each display_id grouping, only one ad_id is which is marked as checked. Can a single ad_id be in multiple display_ids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       display_id   ad_id  clicked\n",
      "15              3  250082        0\n",
      "441            91  250082        0\n",
      "550           112  250082        0\n",
      "6297         1241  250082        0\n",
      "7732         1526  250082        0\n",
      "9539         1874  250082        0\n",
      "11730        2299  250082        0\n",
      "12850        2516  250082        0\n",
      "14723        2878  250082        0\n",
      "15398        3008  250082        0\n",
      "17683        3446  250082        1\n",
      "18346        3579  250082        0\n",
      "19724        3839  250082        0\n",
      "20174        3926  250082        0\n",
      "21556        4196  250082        0\n",
      "22733        4435  250082        0\n",
      "28623        5566  250082        0\n",
      "31803        6194  250082        0\n",
      "32951        6427  250082        0\n",
      "33462        6529  250082        0\n"
     ]
    }
   ],
   "source": [
    "print(clicks_train_og[clicks_train_og.ad_id == 250082].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, a single ad_id can appear in many different display_ids and each ad_id can be clicked on in multiple different display_ids. To learn more about any ad_id, Outbrain says to look into promoted content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ad_id  document_id  campaign_id  advertiser_id\n",
      "0      1         6614            1              7\n",
      "1      2       471467            2              7\n",
      "2      3         7692            3              7\n",
      "3      4       471471            2              7\n",
      "4      5       471472            2              7\n"
     ]
    }
   ],
   "source": [
    "print(promoted_content_og.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promoted content shows which campaign_id from which advertiser_id contains the ad_id. Each campaign_id can contain multiple ad_ids. Can an ad_id be related to multiple document_ids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there multiple rows per ad?: False\n",
      "Is each document related to only one ad?: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Are there multiple rows per ad?: {}\".format(len(promoted_content_og['ad_id'].unique()) != len(promoted_content_og)))\n",
    "print(\"Is each document related to only one ad?: {}\".format(len(promoted_content_og['document_id'].unique()) == len(promoted_content_og)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a document? Outbrain says the document_X.csv files provide context on documents as well as Outbrain's confidence in each respective relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Categories:\n",
      "   document_id  category_id  confidence_level\n",
      "0      1595802         1611              0.92\n",
      "1      1595802         1610              0.07\n",
      "2      1524246         1807              0.92\n",
      "3      1524246         1608              0.07\n",
      "4      1617787         1807              0.92\n",
      "\n",
      "Document Entities:\n",
      "   document_id                         entity_id  confidence_level\n",
      "0      1524246  f9eec25663db4cd83183f5c805186f16          0.672865\n",
      "1      1524246  55ebcfbdaff1d6f60b3907151f38527a          0.399114\n",
      "2      1524246  839907a972930b17b125eb0247898412          0.392096\n",
      "3      1524246  04d8f9a1ad48f126d5806a9236872604          0.213996\n",
      "4      1617787  612a1d17685a498aff4f036c1ee02c16          0.386193\n",
      "\n",
      "Document Topics:\n",
      "   document_id  topic_id  confidence_level\n",
      "0      1595802       140          0.073113\n",
      "1      1595802        16          0.059416\n",
      "2      1595802       143          0.045421\n",
      "3      1595802       170          0.038867\n",
      "4      1524246       113          0.196450\n",
      "\n",
      "Document Meta:\n",
      "   document_id  source_id  publisher_id         publish_time\n",
      "0      1595802          1           603  2016-06-05 00:00:00\n",
      "1      1524246          1           603  2016-05-26 11:00:00\n",
      "2      1617787          1           603  2016-05-27 00:00:00\n",
      "3      1615583          1           603  2016-06-07 00:00:00\n",
      "4      1615460          1           603  2016-06-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Document Categories:\")\n",
    "print(doc_cats_og.head())\n",
    "print(\"\\nDocument Entities:\")\n",
    "print(doc_ents_og.head())\n",
    "print(\"\\nDocument Topics:\")\n",
    "print(doc_topics_og.head())\n",
    "print(\"\\nDocument Meta:\")\n",
    "print(doc_meta_og.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each document_id can be described by a list of category_ids, entity_ids, and topic_ids. Apparently Outbrain either doesn't fully know what is in each document_id or they judge a document is mostly defined by one aspect but has influences of another. As an example: if a document talks about Brad Pitt and refers to his ex-wife as Angelina, we can say the document is 80% about Brad Pitt and 20% about Angelina. Or, alternatively, they are 80% sure the words _Brad Pitt_ refers to the person Brad Pitt and 20% sure the words _Angelina_ refers to the person Angelina Jole. Either interpretation will work for strength of relationship between a document aspect and the document.\n",
    "\n",
    "The meta file is in a different format than the other document files. This one shows specific details on the document. Based on the documentation on Kaggle, source_id is the full home address, publisher_id is the parent of source, and publish_time is when the document was launched on the source. So, for example, webpage with address _edition.cnn.com/20160623/some_news_article/index.html_ has a source_id=edition.cnn.com, a publisher_id=cnn.com, a publish_time=June 23 2016, and a document_id=some_news_article/index.html. These values are masked by numbers, but this example helps keep it straight for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've discussed what is refered to by an ad_id and a document_id, but where does the display_id and user come into this? Remember, our final output is to rank in decending order of click probability which ad_id will be clicked within the context of a specific **display_id**, not document_id. Outbrain says events covers display context. A display in clicks_train or clicks_test means one ad from the display was clicked. Therefore, events covers all events where at least one ad was clicked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          display_id            uuid  document_id   timestamp platform  \\\n",
      "23120121    23120122  3b42aaa4aa8993      1827718  1295999574        1   \n",
      "23120122    23120123  7efccdc2d58fd1      2984543  1295999591        2   \n",
      "23120123    23120124  11f9ac8cee26f2       751048  1295999657        2   \n",
      "23120124    23120125  6bbdc5756789cc       744496  1295999771        2   \n",
      "23120125    23120126  b545c100626cba      2357447  1295999805        2   \n",
      "\n",
      "         geo_location  \n",
      "23120121    US>FL>571  \n",
      "23120122    US>TX>623  \n",
      "23120123    US>GA>524  \n",
      "23120124    US>MI>505  \n",
      "23120125    US>SD>764  \n"
     ]
    }
   ],
   "source": [
    "print(events_og.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many rows are there in events?: 23,120,126\n",
      "How many users are there?: 19,794,967\n",
      "How many documents are there?: 894,060\n",
      "How many displays are there?: 23,120,126\n"
     ]
    }
   ],
   "source": [
    "print('How many rows are there in events?: {:,}'.format(len(events_og)))\n",
    "print('How many users are there?: {:,}'.format(len(events_og.uuid.unique())))\n",
    "print('How many documents are there?: {:,}'.format(len(events_og.document_id.unique())))\n",
    "print('How many displays are there?: {:,}'.format(len(events_og.display_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          display_id            uuid  document_id   timestamp platform  \\\n",
      "11635948    11635949  100008d45879bc      1568841   770542274        1   \n",
      "11633862    11633863  100008d45879bc       619529   770408774        1   \n",
      "4511731      4511732  10000a34905274      2108054   296334056        1   \n",
      "502702        502703  10000a34905274      1798241    38774296        1   \n",
      "11706321    11706322  10000a91d9899d      1068414   774838299        2   \n",
      "20422639    20422640  10000a91d9899d      2834573  1160350596        2   \n",
      "7756431      7756432  10000e5327e96b      2258308   537705911        3   \n",
      "4143201      4143202  10000e5327e96b      2066958   264990674        3   \n",
      "12461877    12461878  10000f9ed3fb23      2592689   827245270        2   \n",
      "12466117    12466118  10000f9ed3fb23      2592689   827433223        2   \n",
      "14557958    14557959  10001c9ddb1a9d      2524505   959420538        1   \n",
      "20556500    20556501  10001c9ddb1a9d      1276858  1165612933        1   \n",
      "9338723      9338724  100022acfa4ad3      2108111   635801430        1   \n",
      "13586921    13586922  100022acfa4ad3      2664253   901020502        1   \n",
      "19267665    19267666  100023e47de95c      1255107   899661671        1   \n",
      "4744949      4744950  100023e47de95c      1683555   308698340        1   \n",
      "18289507    18289508  100023e47de95c      1651023   554953569        1   \n",
      "21077478    21077479  1000283c74a0ab      2872696  1187281350        3   \n",
      "13783144    13783145  1000283c74a0ab      2680013   910405327        3   \n",
      "13473969    13473970  1000283c74a0ab      2584944   895632050        3   \n",
      "\n",
      "         geo_location  \n",
      "11635948    US>MA>506  \n",
      "11633862    US>MA>506  \n",
      "4511731     US>OK>650  \n",
      "502702      US>OK>650  \n",
      "11706321    US>IL>602  \n",
      "20422639           US  \n",
      "7756431     US>UT>770  \n",
      "4143201     US>UT>770  \n",
      "12461877    US>CA>803  \n",
      "12466117    US>CA>803  \n",
      "14557958    US>MO>632  \n",
      "20556500    US>MO>632  \n",
      "9338723     US>MA>506  \n",
      "13586921    US>MA>506  \n",
      "19267665    US>NE>652  \n",
      "4744949     US>NE>652  \n",
      "18289507    US>NE>652  \n",
      "21077478    US>CT>533  \n",
      "13783144    US>MA>506  \n",
      "13473969    US>MA>506  \n"
     ]
    }
   ],
   "source": [
    "seen = set()\n",
    "dup = set()\n",
    "for i in events_og.uuid:\n",
    "    if i in seen:\n",
    "        dup.add(i)\n",
    "    seen.add(i)\n",
    "print(events_og[events_og.uuid.isin(dup)].sort_values(by='uuid')[:20])\n",
    "del seen, dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same user can be shown multiple different displays, but this happens rarely and display_id is unique per user_id * document_id. A display_id is associated with multiple documents which we interpret as a document can be pointed to by multiple displays. But since an ad does the actual pointing, an ad can appear in different displays and point to the same document. This is all pretty confusing so here's a diagram to help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'relationship_diagram.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a5be5ccd0bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relationship_diagram.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'relationship_diagram.png'"
     ]
    }
   ],
   "source": [
    "Image(filename='relationship_diagram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anything interesting about the users in page_views?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             uuid  document_id  timestamp platform geo_location traffic_source\n",
      "0  1fd5f051fba643          120   31905835        1           RS              2\n",
      "1  8557aa9004be3b          120   32053104        1        VN>44              2\n",
      "2  c351b277a358f0          120   54013023        1        KR>12              1\n",
      "3  8205775c5387f9          120   44196592        1        IN>16              2\n",
      "4  9cb0ccd8458371          120   65817371        1    US>CA>807              2\n"
     ]
    }
   ],
   "source": [
    "print(page_views_og.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that clicks are not mentioned here. This indicates page_views is about _any_ page view, not just the ones with a 'success' of a click. Hence the full page_views file is 100GB - there were a lot of documents viewed that never received a click."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what we have, it's time to join the data to create a consolidated dataframe that we can use for machine learning. The relationships are complicated due to potential multiple joins and document_id having two different definitions depending on which table it comes from. Therefore, we join tables in a step-wise fashion, checking that the key field per tale is included as we build up our working dataset. Please see inline comments for what happens at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Documents are highest level item in the dataset.\n",
    "\n",
    "# To find the full set of documents covered by our datasets, \n",
    "# pull in the documents that are in both page_views and promoted_content.\n",
    "# We do this because page_views_sample is only a sample of all the page_views (full dataset is 2 billion rows, 100GB)\n",
    "# and if we try to find the page_views that are associated with our clicks_train (in the intuitive order), we won't\n",
    "# be able to find all the page_views because it's only a sample. \n",
    "\n",
    "# Therefore, we 'reverse engineer' our datasets so that we make sure we grab the information that we CAN get from \n",
    "# our sample, mini datasets.\n",
    "\n",
    "doc_ids = set(page_views_og['document_id']) & set(promoted_content_og['document_id'])\n",
    "\n",
    "# To only view displays and ads that are on our 'master' document list,\n",
    "# filter events to documents that are found in page_views and promoted_content.\n",
    "events = events_og[events_og['document_id'].isin(doc_ids)]\n",
    "\n",
    "# We only want to view ad clicks for displays that have document information.\n",
    "# So we filter clicks to displays found in events.\n",
    "clicks_train = clicks_train_og[clicks_train_og['display_id'].isin(events['display_id'])]\n",
    "\n",
    "# Because clicks may not cover all displays shown in events,\n",
    "# re-filter events to display_id's that are found in clicks_train.\n",
    "events = events_og[events_og['display_id'].isin(clicks_train['display_id'])]\n",
    "\n",
    "# By this point we have a solid list of ads, displays, and documents found in our activity files.\n",
    "# Now filter promoted content to ads found in the filtered training dataset for model fitting.\n",
    "promoted_content = promoted_content_og[promoted_content_og['ad_id'].isin(clicks_train['ad_id'])]\n",
    "\n",
    "# We only need document information about documents we are still considering after prior filters.\n",
    "# Filter document content files to only documents that have made it through to promoted_content for space reasons.\n",
    "doc_cats = doc_cats_og[doc_cats_og['document_id'].isin(promoted_content['document_id'])]\n",
    "doc_ents = doc_ents_og[doc_ents_og['document_id'].isin(promoted_content['document_id'])]\n",
    "doc_meta = doc_meta_og[doc_meta_og['document_id'].isin(promoted_content['document_id'])]\n",
    "doc_topics = doc_topics_og[doc_topics_og['document_id'].isin(promoted_content['document_id'])]\n",
    "\n",
    "# Similarly, filter page views to documents found in events to make this file manageable.\n",
    "# Since we already filtered based on this file in the beginning, this is re-filtering just to get only the data we need\n",
    "page_views = page_views_og[page_views_og['document_id'].isin(events['document_id'])]\n",
    "\n",
    "# Running into a lot of memory errors, so we try to remove all objects that are unnecessary after use\n",
    "del doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our EDA, we are planning to fit a few models, score them on some basic runs, and then optimize the best performing models. First we will create a large feature space, feature engineer some new variables based on EDA and what features we think will be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are predicting on the central data provided through clicks_train, which has a display, the ads in the display, and which ad was clicked. We want to know as much information as possible about the display and the ad, so we start pulling in data from all the other files.\n",
    "\n",
    "First we will pull in information about what display a user saw when they clicked. Events will provide information on what happened at a click event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = clicks_train.merge(events, on='display_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to know more about the ads seen. Remeber: a document can contain multiple displays. In every display, there are multiple ads presented. The document containing the displays will be called document_id_x. Which document the ad is promoting (the document you're taken to when when clicking on the ad) will be document_id_y. Think source (x) and destination (y) documents. All the columns after document_id_y are information about the promoted document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.merge(promoted_content, on='ad_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have meta data about the ads, we need to know more about the promoted document content - what that ad is pointing to. We gather this in the document_X csv's. As noted above, the confidence level deteremines how likely the listed category or topic is actually related to the document.\n",
    "\n",
    "We wanted to duplicate the idea of the CountVectorizer for the 'bag of words' model we used for spam detection, but since we're not counting words in a text, it's a little bit different. We have a 'dictionary' of categories and topics that we use as our 'vocabulary.' Every document has a confidence level for one or more items in the vocabulary. We create a sparse matrix with every topic and category as columns, and every document's associated confidence level value in the respective columns. If the document is not not given a confidence level, we put assume a 0 confidence meaning Outbrain believes the document is unrelated to that category or top.\n",
    "\n",
    "This data on the documents will help us separate ads from one another based on topic/category. For example, why did ad A get clicked instead of ad B? We know ad A referred to document 1 whereas ad B referred to document 2, and now we have general information about the documents the ads referred to. We will merge this information in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# promoted document topics\n",
    "sparsetop = doc_topics.pivot(index='document_id', columns='topic_id', values='confidence_level')\n",
    "sparsetop.columns = ['top_' + str(col) for col in sparsetop.columns]\n",
    "\n",
    "# promoted document categories\n",
    "sparsecat = doc_cats.pivot(index='document_id', columns='category_id', values='confidence_level')\n",
    "sparsecat.columns = ['cat_' + str(col) for col in sparsecat.columns]\n",
    "\n",
    "# join together the topics and categories\n",
    "sparse = sparsetop.join(sparsecat, how='outer')\n",
    "sparse.fillna(0, inplace=True)\n",
    "\n",
    "# remove the separate files to save space but keep the combined file for use with click_teset\n",
    "del sparsetop, sparsecat\n",
    "\n",
    "sparse.reset_index(level=0, inplace=True)\n",
    "\n",
    "# merge in combined category/topics file with data - greatly increases number of columns\n",
    "data = data.merge(sparse, left_on='document_id_y', right_on='document_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know ads are a product of their advertiser, their overall campaign, and the document where they are seen. So we'll add some meta data about how successful the advertiser has been with clicks previously, how successful the campagin has been with clicks previously, and how frequently the document where the ad was seen has been viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# advertiser success information dictionary -- keep for use with click_teset\n",
    "advr_success = dict(zip(data.advertiser_id.unique(),\n",
    "                        [sum(data[data['advertiser_id']==x]['clicked'])/len(data[data['advertiser_id']==x]) for x in data['advertiser_id'].unique()]))\n",
    "# add advertiser success into dataset\n",
    "data['advertiser_perc'] = data['advertiser_id'].map(advr_success)\n",
    "\n",
    "# campagin success information dictionary -- keep for use with click_teset\n",
    "camp_success = dict(zip(data.campaign_id.unique(), \n",
    "                        [sum(data[data['campaign_id']==x]['clicked'])/len(data[data['campaign_id']==x]) for x in data['campaign_id'].unique()]))\n",
    "# add campaign success into dataset\n",
    "data['campaign_perc'] = data['campaign_id'].map(camp_success)\n",
    "\n",
    "# document view frequencies -- keep for use with click_teset\n",
    "doc_view_freq = dict(zip(page_views.document_id.unique(), \n",
    "                         [len(page_views[page_views.document_id==x]) for x in page_views.document_id.unique()]))\n",
    "# add document view frequency into dataset\n",
    "data['docx_view_freq'] = data['document_id_x'].map(doc_view_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, an ad that has been clicked previously is more likely to be clicked again since many people have similar interests. So we'll conclude our dataset by adding a probability that an ad as been previously clicked given how often it's been clicked. This becomes a little try for an ad that has been viewed infrequently, if ever. To account for this, we add regularization with the following two steps:\n",
    "\n",
    "1. if the ad has not been seen before, assign it the mean probability that any ad will be clicked\n",
    "2. for ads that have been seen, add 1 to their click counts and 10 to their total seen counts\n",
    "\n",
    "These two steps will keep an ad that was seen only once from being a 100% or 0% click success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def click_percent(dataset, ad_id, default_result, reg):\n",
    "    '''Returns the posterior probability of ad being clicked.\n",
    "    If ad has not been encountered before, assume mean click'''\n",
    "    \n",
    "    # count number of times ad has been seen\n",
    "    ad_total = len(dataset[dataset['ad_id'] == ad_id])\n",
    "    \n",
    "    # if ad has not been seen, returned the default_results\n",
    "    if ad_total == 0:\n",
    "        return default_result\n",
    "    # otherwise return percentage of times ad has been clicked, adjusted by a regularization term\n",
    "    else:\n",
    "        click_sum = np.sum(dataset[dataset['ad_id'] == ad_id].clicked) + 1.0\n",
    "        return click_sum / (ad_total + reg)\n",
    "\n",
    "    \n",
    "# calculate mean times any ad has been clicked\n",
    "mean_click = np.mean(data[\"clicked\"])\n",
    "\n",
    "# click posterior frequencies -- keep for use with click_teset\n",
    "click_success = dict(zip(data.ad_id.unique(), \n",
    "                         [click_percent(data, x, mean_click, 10.0) for x in data[\"ad_id\"].unique()] ))\n",
    "# add click frequency into dataset\n",
    "data['click_perc'] = data['ad_id'].map(click_success)\n",
    "\n",
    "del mean_click"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with the testing dataset (click_test), we have to be careful not to delete any of the original 330M rows (which equates to 6.2M unique display_ids). This has proved challenging throughout development both from an organization standpoint (making sure we don't accidentally filter out rows) and a size standpoint (330M rows is larger than our little laptops can comfortably handle). \n",
    "\n",
    "Further, we discovered, after much upset, that one of the 200ish categories is in the training dataset but not in the testing dataset. This resulted in our final testing dataset having a different number of columns from the training dataset and angered our ML algorithms. To solve for this issue, we have gathered the basic information about the testing data by joining on events and promoted_content (similar to the start of the training dataset). We pull in the other information later (see below under modeling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull from full events_og to make sure all display information is gathered\n",
    "data_test = clicks_test_og.merge(events_og, on='display_id', how='left')\n",
    "\n",
    "# find the ads from the entire promoted_content_og data and not the one filtered on clicks_train\n",
    "data_test = data_test.merge(promoted_content_og, on='ad_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting training into train and development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels length: 282205\n",
      "data length: (282205, 411)\n",
      "\n",
      "training label shape: (197543, 1)\n",
      "training data shape: (197543, 410)\n",
      "dev label shape: (84662, 1)\n",
      "dev data shape: (84662, 410)\n"
     ]
    }
   ],
   "source": [
    "def split_train_dev(dataset, train_percent = 0.7):\n",
    "    '''Splitting data into test and dev.\n",
    "    If train_precent is left at default, 70% will go into training and 30% into development.\n",
    "    If train_percent = 1, all data will go into training.\n",
    "    If train_percent = 0, all data will go into development.'''\n",
    "\n",
    "    labels = data['clicked']\n",
    "    labels = labels.values.reshape(-1,1)\n",
    "\n",
    "    print ('Labels length:', len(labels))\n",
    "    print ('data length:', data.shape)\n",
    "    print ('')\n",
    "        \n",
    "    train_data = data[:int(train_percent*len(data))].drop('clicked', 1)\n",
    "    dev_data = data[int(train_percent*len(data)):].drop('clicked', 1)\n",
    "\n",
    "    train_labels = labels[:int(train_percent*len(data))]\n",
    "    dev_labels = labels[int(train_percent*len(data)):]\n",
    "\n",
    "    print ('training label shape:', train_labels.shape)\n",
    "    print ('training data shape:', train_data.shape)\n",
    "    print ('dev label shape:', dev_labels.shape)\n",
    "    print ('dev data shape:', dev_data.shape)\n",
    "    \n",
    "    return train_data, train_labels, dev_data, dev_labels\n",
    "\n",
    "train_data, train_labels, dev_data, dev_labels = split_train_dev(data, train_percent = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have three datasets\n",
    "1. train_data, train_labels = 70% of clicks_train dataset. Used for training models.\n",
    "2. dev_data, dev_labels = remaining 30% of clicks_train dataset. Used for measuring accuracy of models on non-train data.\n",
    "3. test_data = clicks_test dataset for final scoring of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to print any of these datasets to csv, uncomment the appropriate line\n",
    "\n",
    "# data_test.to_csv('testingdata.cvs',index=False)\n",
    "# data.to_csv('fulltrainingdata.cvs',index=False)\n",
    "train_data.to_csv('trainingdata.cvs',index=False)\n",
    "train_labels_df= pd.DataFrame(train_labels)\n",
    "train_labels_df.to_csv('traininglabels.cvs',index=False)\n",
    "dev_data.to_csv('developmentdata.cvs',index=False)\n",
    "dev_labels_df= pd.DataFrame(dev_labels)\n",
    "dev_labels_df.to_csv('developmentlabels.cvs',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies a basic linear regression prediction to our prepared data in order to upload it to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahkelley/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with 0 100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-65311925b4f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# find the subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starting with'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mlr_click_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_click_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1964\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2003\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, convert, is_copy)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \"\"\"\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   1370\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2409\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2410\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2411\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   2400\u001b[0m         \u001b[0;34m\"\"\" consolidate _data. if the blocks have changed, then clear the cache \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2402\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2404\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2408\u001b[0m         \u001b[0;34m\"\"\" we are inplace consolidating; return None \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3192\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3199\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3200\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   4187\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4188\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 4189\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   4190\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   4207\u001b[0m         \u001b[0;31m# combination of those slices is a slice, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4208\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4209\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4211\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_vstack\u001b[0;34m(to_stack, dtype)\u001b[0m\n\u001b[1;32m   4253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4254\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarahkelley/anaconda/lib/python3.5/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# clicks_test is too large to run (over 6M rows breaks my poor computer's memory) so we're doing it in batches\n",
    "\n",
    "def lr_output(dataset, model):\n",
    "    \n",
    "    # matching top_X and cat_X categories from training to test. Sparse was created while developing the training dataset.\n",
    "    dataset = dataset.merge(sparse, left_on='document_id_y', right_on='document_id', how='left')\n",
    "    \n",
    "    # Adding meta data from training\n",
    "    dataset['docx_view_freq'] = dataset['document_id_x'].map(doc_view_freq)\n",
    "    dataset['campaign_perc'] = dataset['campaign_id'].map(camp_success)\n",
    "    dataset['advertiser_perc'] = dataset['advertiser_id'].map(advr_success)\n",
    "    dataset['click_perc'] = dataset['ad_id'].map(click_success)\n",
    "    \n",
    "    # fill any nas so the modeling won't get wonky\n",
    "    dataset.fillna(0, inplace=True)\n",
    "    \n",
    "    # check if there are any missing columns between the two datasets\n",
    "    if set(dataset.columns) ^ set(train_data.columns) :\n",
    "        print('We have a problem here!')\n",
    "        \n",
    "    click_prob = pd.DataFrame({'display_id': dataset['display_id'],\n",
    "                               'ad_id': dataset['ad_id'],\n",
    "                               'prediction': lr.predict_proba(dataset[dataset.columns[11:]].fillna(0))[:,1]\n",
    "                              })\n",
    "    \n",
    "    return click_prob\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_data[train_data.columns[11:]].fillna(0), train_labels)\n",
    "\n",
    "lr_click_probs = pd.DataFrame({'display_id': [], \n",
    "                               'ad_id': [], \n",
    "                               'prediction': []})\n",
    "display_ids = data_test.display_id.unique()\n",
    "min_id, max_id, display_max = 0, 100000, len(display_ids)\n",
    "\n",
    "while min_id != display_max:\n",
    "\n",
    "    # keep index within length of display_ids\n",
    "    max_id = min(max_id,display_max)\n",
    "    \n",
    "    # grab that subset of idsplay_ids\n",
    "    display_subset = display_ids[min_id:max_id]\n",
    "    \n",
    "    # find the subset\n",
    "    print('starting with', min_id, max_id)\n",
    "    output = lr_output(data_test[data_test.display_id.isin(display_subset)], lr)\n",
    "    print('output', output.shape)\n",
    "    lr_click_probs = lr_click_probs.append(output, ignore_index = True)\n",
    "    \n",
    "    print('finished with', lr_click_probs.shape)\n",
    "    min_id = max_id\n",
    "    max_id += 100000\n",
    "\n",
    "print(lr_click_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort predictions\n",
    "lr_click_probs.sort_values(by=['display_id','prediction'], ascending=False, inplace=True)\n",
    "\n",
    "# Format the data the way the submission requires\n",
    "output=lr_click_probs.groupby(['display_id'])['ad_id'].apply(lambda x:' '.join(map(str,x))).reset_index()\n",
    "\n",
    "# That's it for the simple solution (prior expectation)!\n",
    "output.to_csv('submission_20161211_1644.cvs',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix/Working space - this is stuff that hasn't been added to the 'full' run.\n",
    "### AKA Lisa's stuff that might go somewhere or might be dumped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lost comments\n",
    "** The below are all good comments that have become detached from their original location, probably from Lisa creating the dataload.py. Keeping them here for now so that they can be reattached as we work on formating the final notebook.**\n",
    "\n",
    "---\n",
    "\n",
    "### Merge information about the documents the ads refer to\n",
    "---\n",
    "\n",
    "creating dictionaries for % of ads clicked for every advertiser and campaign.  \n",
    "purpose: merge to master dataset as a feature for every ad, how often the advertiser and campaign are successful on average.\n",
    "\n",
    "---\n",
    "\n",
    "Add count of page views to every document that an ad appears in (document_id_x) as a feature, could tell us something about likelihood of ads being clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #################3 IGNORE THIS#############3\n",
    "\n",
    "# # events['country'], events['state'] = zip(*map(lambda x: str(x).split('>'), list(events['geo_location'])))\n",
    "\n",
    "# # #temp = map(lambda x: str(x).split('>'), list(page_views['geo_location']))\n",
    "# # print temp[:5]\n",
    "# # zip(*temp[:5]) # removes DMA\n",
    "\n",
    "# #events2 = pd.DataFrame(events['geo_location'].str.split(',').tolist(), columns = ['country', 'state', 'dma'])\n",
    "# events['geo_location'].str.split('>', expand= True)\n",
    "# geo = map(lambda x: str(x).split('>'), events['geo_location'])\n",
    "# zip(*geo)\n",
    "# country = [x[0] for x in geo]\n",
    "# #state = [x[1] for x in geo if x[1]]\n",
    "# if None:\n",
    "#     print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lr_prediction(train_data, train_labels, test_data, test_labels):\n",
    "    '''Returns the array of display_id, ad_id and probability it will be clicked'''\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_data[train_data.columns[11:]].fillna(0), train_labels)\n",
    "    lr_click_prob = lr.predict_proba(test_data[test_data.columns[11:]].fillna(0))[:,1]\n",
    "    lr_score = lr.score(test_data[test_data.columns[11:]].fillna(0), test_labels)\n",
    "    return pd.DataFrame({'display_id': test_data['display_id'],\n",
    "                         'ad_id': test_data['ad_id'],\n",
    "                         'prediction': lr_click_prob\n",
    "                        })\n",
    "lr_output = lr_prediction(train_data, train_labels, dev_data, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first, format the training dataset\n",
    "\n",
    "def click_percent(dataset, ad_id, default_result, reg):\n",
    "    '''Returns the posterior probability of ad being clicked.\n",
    "    If ad has not been encountered before, assume mean click'''\n",
    "    \n",
    "    # count number of times ad has been seen\n",
    "    ad_total = len(dataset[dataset['ad_id'] == ad_id])\n",
    "    \n",
    "    # if ad has not been seen, returned the default_results\n",
    "    if ad_total == 0:\n",
    "        return default_result\n",
    "    # otherwise return percentage of times ad has been clicked, adjusted by a regularization term\n",
    "    else:\n",
    "        click_sum = np.sum(dataset[dataset['ad_id'] == ad_id].clicked) + 1.0\n",
    "        return click_sum / (ad_total + reg)\n",
    "\n",
    "# Merging information aout the displays to master dataset\n",
    "data = clicks_train.merge(events, on='display_id', how='left')\n",
    "# joins information about the display that the user saw\n",
    "# each display has a unique user id, doc id, and timestamp\n",
    "# events has the information about the display (who the user is, which site (document_id) it was on, when it was seen, from where, etc.)\n",
    "\n",
    "# Identifying which documents the ads refer to (aka destination documents)\n",
    "data = data.merge(promoted_content, on='ad_id', how='left')\n",
    "#Now we are merging information on what documents the ads referred to (from source: promoted_content).  \n",
    "#\n",
    "\n",
    "# Gather/bin data about the documents the ads refer to\n",
    "sparsetop = doc_topics.pivot(index='document_id', columns='topic_id', values='confidence_level')\n",
    "sparsetop.columns = ['top_' + str(col) for col in sparsetop.columns]\n",
    "\n",
    "sparsecat = doc_cats.pivot(index='document_id', columns='category_id', values='confidence_level')\n",
    "sparsecat.columns = ['cat_' + str(col) for col in sparsecat.columns]\n",
    "\n",
    "sparse = sparsetop.join(sparsecat, how='outer')\n",
    "sparse.fillna(0, inplace=True)\n",
    "del sparsetop, sparsecat\n",
    "\n",
    "sparse.reset_index(level=0, inplace=True)\n",
    "\n",
    "data = data.merge(sparse, left_on='document_id_y', right_on='document_id', how='left')\n",
    "\n",
    "# adding in advertiser information\n",
    "advr_success = dict(zip(data.advertiser_id.unique(),\n",
    "                        [sum(data[data['advertiser_id']==x]['clicked'])/len(data[data['advertiser_id']==x]) for x in data['advertiser_id'].unique()]))\n",
    "data['advertiser_perc'] = data['advertiser_id'].map(advr_success)\n",
    "\n",
    "# adding in campagin information\n",
    "camp_success = dict(zip(data.campaign_id.unique(), \n",
    "                        [sum(data[data['campaign_id']==x]['clicked'])/len(data[data['campaign_id']==x]) for x in data['campaign_id'].unique()]))\n",
    "data['campaign_perc'] = data['campaign_id'].map(camp_success)\n",
    "\n",
    "# adding in meta about document view frequencies\n",
    "doc_view_freq = dict(zip(page_views.document_id.unique(), \n",
    "                         [len(page_views[page_views.document_id==x]) for x in page_views.document_id.unique()]))\n",
    "data['docx_view_freq'] = data['document_id_x'].map(doc_view_freq)\n",
    "\n",
    "# Adding meta data about prior click percentage\n",
    "mean_click = np.mean(data[\"clicked\"])\n",
    "click_success = dict(zip(data.ad_id.unique(), \n",
    "                         [click_percent(data, x, mean_click, 10.0) for x in data[\"ad_id\"].unique()] ))\n",
    "data['click_perc'] = data['ad_id'].map(click_success)\n",
    "\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
